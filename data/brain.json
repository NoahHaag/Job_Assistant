{
    "logistics": {
        "availability": "I can start immediately (2 weeks notice).",
        "relocation": "I am based in Grafton, MA. I am open to hybrid roles in the Boston area or fully remote roles.",
        "citizenship": "US Citizen, no sponsorship required.",
        "salary_expectations": "I am targeting roles in the $90k - $120k range, depending on the total compensation package and benefits."
    },
    "career_preferences": {
        "ideal_environment": "I thrive in collaborative, fast-paced environments where I can take ownership of features. I value mentorship and code reviews, but I also enjoy the autonomy to research and prototype new solutions.",
        "current_learning": "Currently, I am diving deep into Agentic workflows and Multimodal RAG systems. I'm also improving my knowledge of Cloud Architecture (AWS/GCP) to better deploy the agents I build.",
        "elevator_pitch": "I am a Marine Biologist turned Data Scientist, bringing 8 years of scientific rigor to software engineering. My background leading field teams in high-risk underwater environments taught me adaptability and precision, while my graduate research gave me the statistical foundation to handle messy, real-world data. I don't just write code; I apply the scientific method to build reliable, data-driven systems."
    },
    "marine_biology_context": {
        "research_focus": "My M.S. research focused on the meta-analysis of Artificial Reefs, using R and ArcGIS to synthesize complex spatial data. This required cleaning and harmonizing disparate datasets from decades of literature—a perfect training ground for modern Data Science.",
        "fieldwork_resilience": "As an AAUS Scientific Diver and Research Technician, I managed logistics and safety for offshore expeditions. This experience honed my ability to plan for 'edge cases' and stay calm under pressure—skills that translate directly to handling production incidents in tech.",
        "transferable_skills": [
            "Hypothesis-Driven Debugging (The Scientific Method)",
            "Managing 'Messy' Real-World Data",
            "Project Management in Unpredictable Environments",
            "Technical Communication to Non-Technical Stakeholders"
        ]
    },
    "behavioral_stories": {
             "leadership": {
                   "prompt": "Tell me about a time you led a team.",
                   "story": "STAR Method: While working as a Teaching Assistant for the Three Seas Program, I managed over 20 students in high-risk diving environments. I developed a new safety protocol (Action) that reduced equipment setup time by 30% and ensured zero safety incidents during the semester (Result)."
        },
        "technical_challenge": {
            "prompt": "Describe a difficult technical problem you solved.",
            "story": "STAR Method: In my 'Agent V2' project, I needed to integrate multiple distinct tools (Gmail, Job Search, Resume Updates) into a single autonomous loop. The initial single-threaded approach was too slow and brittle. I architected a new tool execution layer using Python functions as tool for the Gemini 2.0 model, allowing the agent to dynamically select and execute tools in parallel. This not only improved performance but allowed the agent to 'reason' through complex multi-step tasks autonomously."
        },
        "conflict_resolution": {
            "prompt": "Tell me about a disagreement with a colleague.",
            "story": "Certainly. A professional disagreement that comes to mind occurred during my time as a Marine Ecology Research Technician with the Kimbro Lab, specifically during our meta-analysis on Artificial Reef Units. The situation involved me leading the data synthesis, where a critical inclusion criterion for papers was the presence of a 'soft-bottom control.' My colleague, David Kimbro, and I had differing interpretations of this. I initially considered papers with any 'non-natural reef control' sufficient, but David insisted on a stricter interpretation, requiring explicit mention of 'soft-bottom control.' To objectively resolve this, I took the initiative to re-run all relevant analyses, meticulously redoing all figures and statistical tables to present two distinct sets of results: one with broader 'non-natural reef controls' and another strictly adhering to papers explicitly stating 'soft-bottom control.' After reviewing the comparative results, we collectively decided to adopt David's more stringent definition, removing papers that did not explicitly state 'soft-bottom control.' While this meant additional work and a slight reduction in our dataset, it ultimately strengthened the methodological rigor and defensibility of our meta-analysis. This experience reinforced for me the importance of precise definitions in scientific research and the value of thorough, data-driven discussions to ensure the highest quality of work."
        },
        "failure": {
            "prompt": "Tell me about a time you failed.",
            "story": "During a meta-analysis at the Kimbro Lab, I once wrongly coded an R function for standard error, using a static degree of freedom on data requiring multiple, which set us back two weeks; it taught me the critical importance of rigorous code review and incremental validation, significantly improving our analytical reliability."
        }
    },
    "technical_opinions": {
        "favorite_stack": "I love Python for its ecosystem. My go-to stack right now is LangChain or Google ADK for the backend logic, Streamlit for rapid UI prototyping, and ChromaDB for vector storage.",
        "why_ai": "I believe AI is the next frontier for environmental science. I want to build agents that can process ecological data faster than humanly possible to aid in conservation efforts."
    },
    "hobbies_and_personality": {
        "hobbies": "Outside of coding, I am an avid SCUBA diver (Master Diver) and volunteer as a Conservation Commissioner. I love complex systems, whether they are underwater ecosystems or distributed software architectures.",
        "fun_facts": [
            "I was once a balloon holder for the Macy's Thanksgiving Day Parade.",
            "I have logged over 100 dives, including research dives in zero-visibility conditions.",
            "I taught myself Python initially to analyze marine ecological data better than Excel allowed."
        ]
    },
    "artifacts": {
        "agent_v2": {
            "trigger_words": ["agent v2", "autonomous loop", "tool execution", "agent architecture", "gemini"],
            "image_path": "public/agent_v2_visual.png",
            "caption": "Architecture concept of my Agent V2, handling parallel tool execution.",
            "link": "https://github.com/NoahHaag/Agent_V2"
        },
        "meta_analysis_map": {
            "trigger_words": ["gis", "spatial data", "locations", "global study", "arcgis", "map"],
            "image_path": "public/study_map.png",
            "caption": "Global distribution of studies synthesized in my meta-analysis (ArcGIS output)."
        },
        "reef_context": {
            "trigger_words": ["artificial reef", "kimbro lab", "scuba", "fieldwork", "diving", "underwater", "environment"],
            "image_path": "public/reef_context.png",
            "caption": "The complex underwater environment of Artificial Reefs."
        }
    }
}